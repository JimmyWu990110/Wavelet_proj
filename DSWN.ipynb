{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNidGL9so-Cz",
        "outputId": "fc6bb305-dd5f-4e5c-e52b-e12c25def205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyWavelets in ./.venv/lib/python3.12/site-packages (1.8.0)\n",
            "Requirement already satisfied: pytorch_wavelets in ./.venv/lib/python3.12/site-packages (1.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in ./.venv/lib/python3.12/site-packages (from PyWavelets) (2.1.3)\n",
            "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from pytorch_wavelets) (1.17.0)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from pytorch_wavelets) (2.5.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (4.12.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (2024.10.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (75.6.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch->pytorch_wavelets) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch->pytorch_wavelets) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->pytorch_wavelets) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install PyWavelets pytorch_wavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9qkZwYcnDoo0"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from pytorch_wavelets import DWTForward, DWTInverse\n",
        "\n",
        "\n",
        "class Basicconv(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, inchannel, outchannel, groups=1):\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Conv2d(\n",
        "            inchannel, outchannel, kernel_size=3, padding=1, groups=groups)\n",
        "        self.act = torch.nn.PReLU()\n",
        "        self.nom = torch.nn.GroupNorm(groups, outchannel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.nom(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Bottleneck(torch.nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, groups=1):\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Conv2d(inchannel, outchannel, kernel_size=1, groups=groups)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCRblock(torch.nn.Module):\n",
        "    def __init__(self, inchannel, groups=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = Basicconv(inchannel, inchannel//2, groups=groups)\n",
        "        self.conv2 = Basicconv(inchannel//2 + inchannel, inchannel//2)\n",
        "        self.conv3 = Basicconv(2 * inchannel, inchannel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = torch.cat([x, x1], dim=1)\n",
        "        x2 = self.conv2(x2)\n",
        "        x2 = torch.cat([x1, x2, x], dim=1)\n",
        "        x3 = self.conv3(x2)\n",
        "        x = x3 + x\n",
        "        return x\n",
        "\n",
        "\n",
        "class finalneck(torch.nn.Module):\n",
        "    def __init__(self, inchannel, outchannel):\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Conv2d(\n",
        "            inchannel, outchannel, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class finalcombine(torch.nn.Module):\n",
        "    def __init__(self, inchannel, wave=\"Haar\", groups=False):\n",
        "        super().__init__()\n",
        "        self.groups = groups\n",
        "        self.c00 = Basicconv(inchannel=inchannel,  outchannel=160)\n",
        "        self.DWT = DWTForward(1, wave, \"symmetric\")\n",
        "        self.IDWT = DWTInverse(wave, \"symmetric\")\n",
        "        self.c1 = Bottleneck(inchannel=320, outchannel=320)\n",
        "        self.d1 = Bottleneck(inchannel=320, outchannel=320)\n",
        "        self.c2 = DCRblock(inchannel=320)\n",
        "        self.d2 = DCRblock(inchannel=320)\n",
        "        self.c3 = DCRblock(inchannel=320)\n",
        "        self.d3 = DCRblock(inchannel=320)\n",
        "        self.c4 = finalneck(inchannel=320, outchannel=3)\n",
        "        self.d4 = finalneck(inchannel=320, outchannel=3)\n",
        "        self.c11 = Basicconv(\n",
        "            inchannel=inchannel * 4,  outchannel=256, groups=4 if groups else 1)\n",
        "        self.c12 = Bottleneck(inchannel=512, outchannel=512)\n",
        "        self.c13 = DCRblock(inchannel=512)\n",
        "        self.c14 = finalneck(inchannel=512, outchannel=640)\n",
        "        self.c21 = Basicconv(inchannel=inchannel * 4 * 4,\n",
        "                             outchannel=256, groups=4 if groups else 1)\n",
        "        self.c22 = Bottleneck(inchannel=512, outchannel=512)\n",
        "        self.c23 = DCRblock(inchannel=512)\n",
        "        self.c24 = finalneck(inchannel=512, outchannel=1024)\n",
        "        self.c31 = Basicconv(inchannel=inchannel * 4 * 4 * 4,\n",
        "                             outchannel=256, groups=4 if groups else 1)\n",
        "        self.c32 = DCRblock(inchannel=256, groups=4 if groups else 1)\n",
        "        self.c33 = finalneck(inchannel=256, outchannel=1024)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x00 = self.c00(x)\n",
        "        b, c, w, h = x.shape\n",
        "        w = w // 2\n",
        "        h = h // 2\n",
        "        xl, xh = self.DWT(x)\n",
        "        xh = xh[0][:, :, :, :w, :h]\n",
        "        xl = xl[:, :, :w, :h]\n",
        "        b, c, _, w, h = xh.shape\n",
        "        xh = xh.reshape(b, 3*c, w, h)\n",
        "        x1 = torch.cat([xl, xh], dim=1)\n",
        "\n",
        "        x11 = self.c11(x1)\n",
        "        b, c, w, h = x1.shape\n",
        "        w = w // 2\n",
        "        h = h // 2\n",
        "        xl, xh = self.DWT(x1)\n",
        "        xh = xh[0][:, :, :, :w, :h]\n",
        "        xl = xl[:, :, :w, :h]\n",
        "        b, c, _, w, h = xh.shape\n",
        "        xh = xh.reshape(b, 3*c, w, h)\n",
        "        x2 = torch.cat([xl, xh], dim=1)\n",
        "\n",
        "        x21 = self.c21(x2)\n",
        "        b, c, w, h = x2.shape\n",
        "        w = w // 2\n",
        "        h = h // 2\n",
        "        xl, xh = self.DWT(x2)\n",
        "        xh = xh[0][:, :, :, :w, :h]\n",
        "        xl = xl[:, :, :w, :h]\n",
        "        b, c, _, w, h = xh.shape\n",
        "        xh = xh.reshape(b, 3*c, w, h)\n",
        "        x3 = torch.cat([xl, xh], dim=1)\n",
        "\n",
        "        x31 = self.c31(x3)\n",
        "        x32 = self.c32(x31)\n",
        "        x33 = self.c33(x32)\n",
        "        c = x33.shape[1] // 4\n",
        "        xl = x33[:, :c]\n",
        "        xh = x33[:, c:]\n",
        "        b, c, w, h = xl.shape\n",
        "        xh = [xh.reshape(b, c, 3, w, h)]\n",
        "        w = w * 2\n",
        "        h = h * 2\n",
        "        xi = self.IDWT((xl, xh))\n",
        "        xi = torch.nn.functional.pad(\n",
        "            xi, (0, h-xi.shape[2], 0, w-xi.shape[3]), mode=\"reflect\")\n",
        "        x21 = torch.cat([x21, xi], dim=1)\n",
        "        x22 = self.c22(x21)\n",
        "        x23 = self.c23(x22)\n",
        "        x24 = self.c24(x23)\n",
        "        c = x24.shape[1] // 4\n",
        "        xl = x24[:, :c]\n",
        "        xh = x24[:, c:]\n",
        "        b, c, w, h = xl.shape\n",
        "        xh = [xh.reshape(b, c, 3, w, h)]\n",
        "        w *= 2\n",
        "        h *= 2\n",
        "        xi = self.IDWT((xl, xh))\n",
        "        xi = torch.nn.functional.pad(\n",
        "            xi, (0, h-xi.shape[2], 0, w-xi.shape[3]), mode=\"reflect\")\n",
        "        x11 = torch.cat([x11, xi], dim=1)\n",
        "        x12 = self.c12(x11)\n",
        "        x13 = self.c13(x12)\n",
        "        x14 = self.c14(x13)\n",
        "        c = x14.shape[1] // 4\n",
        "        xl = x14[:, :c]\n",
        "        xh = x14[:, c:]\n",
        "        b, c, w, h = xl.shape\n",
        "        xh = [xh.reshape(b, c, 3, w, h)]\n",
        "        w *= 2\n",
        "        h *= 2\n",
        "        xi = self.IDWT((xl, xh))\n",
        "        xi = torch.nn.functional.pad(\n",
        "            xi, (0, w - xi.shape[2], 0, h - xi.shape[3]), mode=\"reflect\")\n",
        "        x01 = torch.cat([x00, xi], dim=1)\n",
        "        xc1 = self.c1(x01)\n",
        "        xc2 = self.c2(xc1) + xc1\n",
        "        xc3 = self.c3(xc2) + xc2\n",
        "        xc4 = self.c4(xc3)\n",
        "        xc4 = torch.nn.functional.tanh(xc4)\n",
        "        xd1 = self.d1(x01)\n",
        "        xd2 = self.d2(xd1) + xd1\n",
        "        xd3 = self.d3(xd2) + xd2\n",
        "        xd4 = self.d4(xd3)\n",
        "        xd4 = x - xd4\n",
        "        output = (xd4 + xc4)/2\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DT8e5Z6defia"
      },
      "outputs": [],
      "source": [
        "from utils import train, test\n",
        "from BSD import BSDDataset\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(4623)\n",
        "torch.cuda.manual_seed(4623)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "image_size = 256\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "lr = 1e-4\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "base_dir=\"\"\n",
        "\n",
        "train_set = BSDDataset(base_dir=base_dir, split=\"train\")\n",
        "test_set = BSDDataset(base_dir=base_dir, split=\"test\")\n",
        "\n",
        "\n",
        "def rgb_to_ycbcr(img):\n",
        "    M = torch.tensor([[ 0.2990,     0.5870,     0.1140    ],\n",
        "                      [-0.168736, -0.331264,    0.5       ],\n",
        "                      [ 0.5,      -0.418688,   -0.081312  ]], dtype=img.dtype, device=img.device)\n",
        "    bias = torch.tensor([0.0, 0.5, 0.5], dtype=img.dtype, device=img.device).view(3, 1, 1)\n",
        "    ycbcr = torch.einsum('bchw,mc->bmhw', img, M) + bias\n",
        "    return ycbcr\n",
        "\n",
        "def ycbcr_to_rgb(ycbcr):\n",
        "    M_inv = torch.tensor([[1.0,  0.0,       1.402],\n",
        "                          [1.0, -0.344136, -0.714136],\n",
        "                          [1.0,  1.772,    0.0     ]], dtype=ycbcr.dtype, device=ycbcr.device)\n",
        "    bias = torch.tensor([0.0, -0.5, -0.5], dtype=ycbcr.dtype, device=ycbcr.device).view(3, 1, 1)\n",
        "    rgb = torch.einsum('bchw,mc->bmhw', ycbcr + bias, M_inv)\n",
        "    return rgb\n",
        "\n",
        "def compute_loss(model, images, noise_range=(1, 60), residual=False, luminance=False):\n",
        "    noise_level = torch.randint(noise_range[0], noise_range[1], (1,)).item()\n",
        "    noisy_images = images + (noise_level / 255.0) * torch.randn_like(images)\n",
        "    images = images.to(device)  # move to GPU\n",
        "    noisy_images = torch.clamp(noisy_images, 0, 1)\n",
        "    noisy_images = noisy_images.to(device)\n",
        "    if luminance:\n",
        "        images = rgb_to_ycbcr(images)[:, :1]\n",
        "        noisy_images = rgb_to_ycbcr(noisy_images)[:, :1]\n",
        "    outputs = model(noisy_images)  # forward\n",
        "    outputs = outputs\n",
        "    if residual:\n",
        "        loss = criterion(outputs, noisy_images - images)\n",
        "        return loss\n",
        "    loss = criterion(outputs, images)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def denoise(model, noisy_img, residual=False, luminance=False):\n",
        "    if luminance:\n",
        "        target_img = rgb_to_ycbcr(noisy_img)\n",
        "        noisy_img = target_img[:, :1]\n",
        "    if residual:\n",
        "        outputs = noisy_img - model(noisy_img)\n",
        "    else:\n",
        "        outputs = model(noisy_img)  # forward\n",
        "    if luminance:\n",
        "        outputs = torch.cat([outputs, target_img[:, 1:]], dim=1)\n",
        "        outputs = ycbcr_to_rgb(outputs)\n",
        "    outputs = torch.clamp(outputs, 0, 1)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def experiment(model_name, residual=False, luminance=False, groups=False):\n",
        "    if luminance:\n",
        "        model = finalcombine(inchannel=1, groups=groups).to(device)\n",
        "    else:\n",
        "        model = finalcombine(inchannel=3, groups=groups).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    train(model, optimizer, epochs, train_set, test_set, batch_size, model_name, compute_loss=compute_loss, residual=residual, luminance=luminance)\n",
        "    for noise_level in [10, 25, 50]:\n",
        "        test(model, test_set, batch_size, model_name, noise_level, denoise=denoise, residual=residual, luminance=luminance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onPLNajZsVNc"
      },
      "source": [
        "All Combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "xHXUd7Hqrx9_",
        "outputId": "e34befe5-4cac-4004-8fae-69bb4c060c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSWN\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "model_name = \"DSWN\"\n",
        "residual = True\n",
        "luminance = True\n",
        "groups=True\n",
        "\n",
        "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ablation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJf6EI5Prymy"
      },
      "outputs": [],
      "source": [
        "model_name = \"DSWN-no-residual\"\n",
        "residual = False\n",
        "luminance = True\n",
        "groups=True\n",
        "\n",
        "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QNWCuGjry71"
      },
      "outputs": [],
      "source": [
        "model_name = \"DSWN-no-luminance\"\n",
        "residual = True\n",
        "luminance = False\n",
        "groups=True\n",
        "\n",
        "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"DSWN-no-groups\"\n",
        "residual = True\n",
        "luminance = True\n",
        "groups=False\n",
        "\n",
        "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
