{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: pytorch_wavelets in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-image in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.5.3.56 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from opencv-python-headless==4.5.3.56) (1.24.3)\n",
      "Requirement already satisfied: six in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pytorch_wavelets) (1.16.0)\n",
      "Requirement already satisfied: torch in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pytorch_wavelets) (2.1.0+cu118)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (1.11.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: filelock in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (2024.9.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from jinja2->torch->pytorch_wavelets) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from sympy->torch->pytorch_wavelets) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyWavelets pytorch_wavelets scikit-image opencv-python-headless==4.5.3.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "import torch\n",
    "from diffusion.diffusion import Diffusion\n",
    "from diffusion.wavelet_diffusion import WaveDiffusion\n",
    "from torch.utils.data import DataLoader\n",
    "from BSD import BSDDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_size = 256\n",
    "epochs = 50\n",
    "batch_size = 4\n",
    "time_range = 1000\n",
    "lr = 1e-4\n",
    "\n",
    "base_dir=\"\"\n",
    "\n",
    "train_set = BSDDataset(base_dir=base_dir, split=\"train\")\n",
    "test_set = BSDDataset(base_dir=base_dir, split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Diffusion(image_size=image_size, image_channels=3, time_range=time_range, device=device).to(device)\n",
    "model_name = \"Diffuser Baseline\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_loss_all = []\n",
    "test_loss_all = []\n",
    "\n",
    "bar = tqdm(range(epochs))\n",
    "\n",
    "output_dir = os.path.join(base_dir, \"results_BSD\", model_name)\n",
    "model_dir = os.path.join(output_dir, \"model.pt\")\n",
    "if os.path.exists(model_dir):\n",
    "    model.load_state_dict(torch.load(model_dir).state_dict())\n",
    "else:\n",
    "    for epoch in bar:\n",
    "        # training\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, _ = data\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            bar.set_postfix({\"Step\": str(epoch * len(train_loader) + i + 1) + \"/\" + str(epochs * len(train_loader)), \"training loss\": format(train_loss, \".3f\")})\n",
    "        train_loss_all.append(train_loss/len(train_set))\n",
    "        # testing\n",
    "        test_loss = 0\n",
    "        model.eval()\n",
    "        for data in test_loader:\n",
    "            images, _ = data\n",
    "            with torch.no_grad():\n",
    "                loss = model.loss(images)\n",
    "            test_loss += loss.item()\n",
    "        bar.set_postfix({\"Epoch\": epoch+1, \"testing loss\": format(test_loss, \".3f\")})\n",
    "        test_loss_all.append(test_loss/len(test_set))\n",
    "    \n",
    "    # save model and results\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    torch.save(model, os.path.join(output_dir, \"model.pt\"))\n",
    "    np.save(os.path.join(output_dir, \"train_loss.npy\"), np.array(train_loss_all))\n",
    "    np.save(os.path.join(output_dir, \"test_loss.npy\"), np.array(test_loss_all))\n",
    "    \n",
    "    plt.plot(train_loss_all, label=\"training loss\")\n",
    "    plt.plot(test_loss_all, label=\"testing loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, \"loss.png\"), format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_level: 10\n",
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:06,  6.31s/it]\u001b[A\n",
      "2it [00:09,  4.34s/it]\u001b[A\n",
      "3it [00:12,  3.70s/it]\u001b[A\n",
      "4it [00:15,  3.41s/it]\u001b[A\n",
      "5it [00:18,  3.25s/it]\u001b[A\n",
      "6it [00:21,  3.14s/it]\u001b[A\n",
      "7it [00:24,  3.08s/it]\u001b[A\n",
      "8it [00:26,  3.04s/it]\u001b[A\n",
      "9it [00:29,  3.01s/it]\u001b[A\n",
      "10it [00:32,  3.00s/it]\u001b[A\n",
      "11it [00:35,  2.99s/it]\u001b[A\n",
      "12it [00:38,  2.98s/it]\u001b[A\n",
      "13it [00:41,  2.97s/it]\u001b[A\n",
      "14it [00:44,  2.97s/it]\u001b[A\n",
      "15it [00:47,  2.96s/it]\u001b[A\n",
      "16it [00:50,  2.97s/it]\u001b[A\n",
      "17it [00:53,  2.97s/it]\u001b[A\n",
      "18it [00:56,  2.96s/it]\u001b[A\n",
      "19it [00:59,  2.96s/it]\u001b[A\n",
      "20it [01:02,  2.96s/it]\u001b[A\n",
      "21it [01:05,  2.96s/it]\u001b[A\n",
      "22it [01:08,  2.96s/it]\u001b[A\n",
      "23it [01:11,  2.95s/it]\u001b[A\n",
      "24it [01:14,  2.96s/it]\u001b[A\n",
      "25it [01:17,  3.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR noisy: 31.71 +- 0.16\n",
      "SSIM noisy: 0.840 +- 0.066\n",
      "PSNR denoised: 32.15 +- 1.15\n",
      "SSIM denoised: 0.886 +- 0.026\n",
      "noise_level: 25\n",
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:08,  8.74s/it]\u001b[A\n",
      "2it [00:14,  6.99s/it]\u001b[A\n",
      "3it [00:20,  6.43s/it]\u001b[A\n",
      "4it [00:26,  6.16s/it]\u001b[A\n",
      "5it [00:31,  6.01s/it]\u001b[A\n",
      "6it [00:37,  5.92s/it]\u001b[A\n",
      "7it [00:43,  5.87s/it]\u001b[A\n",
      "8it [00:49,  5.83s/it]\u001b[A\n",
      "9it [00:54,  5.80s/it]\u001b[A\n",
      "10it [01:00,  5.79s/it]\u001b[A\n",
      "11it [01:06,  5.83s/it]\u001b[A\n",
      "12it [01:12,  5.80s/it]\u001b[A\n",
      "13it [01:17,  5.78s/it]\u001b[A\n",
      "14it [01:23,  5.77s/it]\u001b[A\n",
      "15it [01:29,  5.76s/it]\u001b[A\n",
      "16it [01:35,  5.76s/it]\u001b[A\n",
      "17it [01:40,  5.76s/it]\u001b[A\n",
      "18it [01:46,  5.76s/it]\u001b[A\n",
      "19it [01:52,  5.76s/it]\u001b[A\n",
      "20it [01:58,  5.76s/it]\u001b[A\n",
      "21it [02:03,  5.75s/it]\u001b[A\n",
      "22it [02:09,  5.75s/it]\u001b[A\n",
      "23it [02:15,  5.83s/it]\u001b[A\n",
      "24it [02:21,  5.80s/it]\u001b[A\n",
      "25it [02:27,  5.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR noisy: 23.91 +- 0.26\n",
      "SSIM noisy: 0.557 +- 0.116\n",
      "PSNR denoised: 28.06 +- 1.04\n",
      "SSIM denoised: 0.776 +- 0.041\n",
      "noise_level: 50\n",
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:14, 14.51s/it]\u001b[A\n",
      "2it [00:25, 12.63s/it]\u001b[A\n",
      "3it [00:37, 12.03s/it]\u001b[A\n",
      "4it [00:48, 11.75s/it]\u001b[A\n",
      "5it [00:59, 11.64s/it]\u001b[A\n",
      "6it [01:11, 11.53s/it]\u001b[A\n",
      "7it [01:22, 11.46s/it]\u001b[A\n",
      "8it [01:33, 11.43s/it]\u001b[A\n",
      "9it [01:45, 11.40s/it]\u001b[A\n",
      "10it [01:56, 11.38s/it]\u001b[A\n",
      "11it [02:07, 11.36s/it]\u001b[A\n",
      "12it [02:19, 11.35s/it]\u001b[A\n",
      "13it [02:30, 11.35s/it]\u001b[A\n",
      "14it [02:41, 11.34s/it]\u001b[A\n",
      "15it [02:53, 11.34s/it]\u001b[A\n",
      "16it [03:04, 11.34s/it]\u001b[A\n",
      "17it [03:15, 11.33s/it]\u001b[A\n",
      "18it [03:27, 11.33s/it]\u001b[A\n",
      "19it [03:38, 11.33s/it]\u001b[A\n",
      "20it [03:49, 11.33s/it]\u001b[A\n",
      "21it [04:01, 11.34s/it]\u001b[A\n",
      "22it [04:12, 11.39s/it]\u001b[A\n",
      "23it [04:24, 11.37s/it]\u001b[A\n",
      "24it [04:35, 11.36s/it]\u001b[A\n",
      "25it [04:46, 11.47s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR noisy: 18.31 +- 0.29\n",
      "SSIM noisy: 0.323 +- 0.103\n",
      "PSNR denoised: 24.40 +- 0.98\n",
      "SSIM denoised: 0.631 +- 0.053\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "test_set = BSDDataset(base_dir=base_dir, split=\"test\")\n",
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "for noise_level, time in [(10, 10), (25, 20), (50, 40)]:\n",
    "    print(\"noise_level:\", noise_level)\n",
    "    output_dir = os.path.join(base_dir, \"results_BSD\", model_name + str(noise_level))\n",
    "    original_path = os.path.join(output_dir, \"original_images\")\n",
    "    noisy_path = os.path.join(output_dir, \"noisy_images\")\n",
    "    denoised_path = os.path.join(output_dir, \"denoised_images\")\n",
    "    os.makedirs(original_path, exist_ok=True)\n",
    "    os.makedirs(noisy_path, exist_ok=True)\n",
    "    os.makedirs(denoised_path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    model.to(device)\n",
    "    \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for j, data in tqdm(enumerate(test_loader, 0)):\n",
    "            images, _ = data\n",
    "            noisy_images = images + (noise_level/255)*torch.randn(*images.shape)\n",
    "            noisy_images = np.clip(noisy_images, 0, 1)\n",
    "            images = images.to(device) # move to GPU\n",
    "            noisy_images = noisy_images.to(device)\n",
    "            outputs = model.generational_denoise(noisy_images, time) # forward\n",
    "            images = images.cpu().detach().numpy()\n",
    "            noisy_images = noisy_images.cpu().detach().numpy()\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            for i in range(len(images)):\n",
    "                image = 255 * np.transpose(images[i], (1,2,0))\n",
    "                noisy_image = 255 * np.transpose(noisy_images[i], (1,2,0))\n",
    "                output = 255 * np.transpose(outputs[i], (1,2,0))\n",
    "                cv2.imwrite(os.path.join(original_path, str(counter)+\".png\"), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "                cv2.imwrite(os.path.join(noisy_path, str(counter)+\".png\"), cv2.cvtColor(noisy_image, cv2.COLOR_RGB2BGR))\n",
    "                cv2.imwrite(os.path.join(denoised_path, str(counter)+\".png\"), cv2.cvtColor(output, cv2.COLOR_RGB2BGR))\n",
    "                counter += 1\n",
    "            if counter > 100:\n",
    "                break\n",
    "    \n",
    "    PSNR_noisy = []\n",
    "    SSIM_noisy = []\n",
    "    PSNR_denoised = []\n",
    "    SSIM_denoised = []\n",
    "    for i in range(len(os.listdir(original_path))):\n",
    "        image = cv2.imread(os.path.join(original_path, str(i)+\".png\"), 0)\n",
    "        noisy_image = cv2.imread(os.path.join(noisy_path, str(i)+\".png\"), 0)\n",
    "        denoised_image = cv2.imread(os.path.join(denoised_path, str(i)+\".png\"), 0)\n",
    "        PSNR_noisy.append(peak_signal_noise_ratio(image, noisy_image))\n",
    "        SSIM_noisy.append(structural_similarity(image, noisy_image))\n",
    "        PSNR_denoised.append(peak_signal_noise_ratio(image, denoised_image))\n",
    "        SSIM_denoised.append(structural_similarity(image, denoised_image))\n",
    "    print(\"PSNR noisy:\", format(np.mean(PSNR_noisy), \".2f\"), \"+-\", format(np.std(PSNR_noisy), \".2f\"))\n",
    "    print(\"SSIM noisy:\", format(np.mean(SSIM_noisy), \".3f\"), \"+-\", format(np.std(SSIM_noisy), \".3f\"))\n",
    "    print(\"PSNR denoised:\", format(np.mean(PSNR_denoised), \".2f\"), \"+-\", format(np.std(PSNR_denoised), \".2f\"))\n",
    "    print(\"SSIM denoised:\", format(np.mean(SSIM_denoised), \".3f\"), \"+-\", format(np.std(SSIM_denoised), \".3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WaveDiffusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveDiffusion(image_size=image_size, image_channels=3, time_range=time_range, device=device).to(device)\n",
    "model_name = \"WaveDiffusion\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:21<?, ?it/s, Step=84/5000, training loss=41.980]"
     ]
    }
   ],
   "source": [
    "train_loss_all = []\n",
    "test_loss_all = []\n",
    "\n",
    "bar = tqdm(range(epochs))\n",
    "\n",
    "for epoch in bar:\n",
    "    # training\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, _ = data\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        bar.set_postfix({\"Step\": str(epoch * len(train_loader) + i + 1) + \"/\" + str(epochs * len(train_loader)), \"training loss\": format(train_loss, \".3f\")})\n",
    "    train_loss_all.append(train_loss/len(train_set))\n",
    "    # testing\n",
    "    test_loss = 0\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        images, _ = data\n",
    "        with torch.no_grad():\n",
    "            loss = model.loss(images)\n",
    "        test_loss += loss.item()\n",
    "    bar.set_postfix({\"Epoch\": epoch+1, \"testing loss\": format(test_loss, \".3f\")})\n",
    "    test_loss_all.append(test_loss/len(test_set))\n",
    "\n",
    "# save model and results\n",
    "output_dir = os.path.join(base_dir, \"results_BSD\", model_name)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "torch.save(model, os.path.join(output_dir, \"model.pt\"))\n",
    "np.save(os.path.join(output_dir, \"train_loss.npy\"), np.array(train_loss_all))\n",
    "np.save(os.path.join(output_dir, \"test_loss.npy\"), np.array(test_loss_all))\n",
    "\n",
    "plt.plot(train_loss_all, label=\"training loss\")\n",
    "plt.plot(test_loss_all, label=\"testing loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, \"loss.png\"), format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "test_set = BSDDataset(base_dir=base_dir, split=\"test\")\n",
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "for noise_level, time in [(10, 10), (25, 20), (50, 40)]:\n",
    "    print(\"noise_level:\", noise_level)\n",
    "    output_dir = os.path.join(base_dir, \"results_BSD\", model_name + str(noise_level))\n",
    "    original_path = os.path.join(output_dir, \"original_images\")\n",
    "    noisy_path = os.path.join(output_dir, \"noisy_images\")\n",
    "    denoised_path = os.path.join(output_dir, \"denoised_images\")\n",
    "    os.makedirs(original_path, exist_ok=True)\n",
    "    os.makedirs(noisy_path, exist_ok=True)\n",
    "    os.makedirs(denoised_path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    model.to(device)\n",
    "    \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for j, data in tqdm(enumerate(test_loader, 0)):\n",
    "            images, _ = data\n",
    "            noisy_images = images + (noise_level/255)*torch.randn(*images.shape)\n",
    "            noisy_images = np.clip(noisy_images, 0, 1)\n",
    "            images = images.to(device) # move to GPU\n",
    "            noisy_images = noisy_images.to(device)\n",
    "            outputs = model.generational_denoise(noisy_images, time) # forward\n",
    "            images = images.cpu().detach().numpy()\n",
    "            noisy_images = noisy_images.cpu().detach().numpy()\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            for i in range(len(images)):\n",
    "                image = 255 * np.transpose(images[i], (1,2,0))\n",
    "                noisy_image = 255 * np.transpose(noisy_images[i], (1,2,0))\n",
    "                output = 255 * np.transpose(outputs[i], (1,2,0))\n",
    "                cv2.imwrite(os.path.join(original_path, str(counter)+\".png\"), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "                cv2.imwrite(os.path.join(noisy_path, str(counter)+\".png\"), cv2.cvtColor(noisy_image, cv2.COLOR_RGB2BGR))\n",
    "                cv2.imwrite(os.path.join(denoised_path, str(counter)+\".png\"), cv2.cvtColor(output, cv2.COLOR_RGB2BGR))\n",
    "                counter += 1\n",
    "            if counter > 100:\n",
    "                break\n",
    "    \n",
    "    PSNR_noisy = []\n",
    "    SSIM_noisy = []\n",
    "    PSNR_denoised = []\n",
    "    SSIM_denoised = []\n",
    "    for i in range(len(os.listdir(original_path))):\n",
    "        image = cv2.imread(os.path.join(original_path, str(i)+\".png\"), 0)\n",
    "        noisy_image = cv2.imread(os.path.join(noisy_path, str(i)+\".png\"), 0)\n",
    "        denoised_image = cv2.imread(os.path.join(denoised_path, str(i)+\".png\"), 0)\n",
    "        PSNR_noisy.append(peak_signal_noise_ratio(image, noisy_image))\n",
    "        SSIM_noisy.append(structural_similarity(image, noisy_image))\n",
    "        PSNR_denoised.append(peak_signal_noise_ratio(image, denoised_image))\n",
    "        SSIM_denoised.append(structural_similarity(image, denoised_image))\n",
    "    print(\"PSNR noisy:\", format(np.mean(PSNR_noisy), \".2f\"), \"+-\", format(np.std(PSNR_noisy), \".2f\"))\n",
    "    print(\"SSIM noisy:\", format(np.mean(SSIM_noisy), \".3f\"), \"+-\", format(np.std(SSIM_noisy), \".3f\"))\n",
    "    print(\"PSNR denoised:\", format(np.mean(PSNR_denoised), \".2f\"), \"+-\", format(np.std(PSNR_denoised), \".2f\"))\n",
    "    print(\"SSIM denoised:\", format(np.mean(SSIM_denoised), \".3f\"), \"+-\", format(np.std(SSIM_denoised), \".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
