{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5057ba52-62d1-4f37-b1d7-889e7751efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "\n",
    "class ImageAttentionBlock(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, image_size, num_head=4):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.image_size = image_size\n",
    "        self.layer_norm = torch.nn.LayerNorm([hidden_dim])\n",
    "        self.att = torch.nn.MultiheadAttention(hidden_dim, num_head, batch_first=True)\n",
    "        self.feed_forward = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm([hidden_dim]),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, C, H, W]\n",
    "        x = x.reshape(-1, self.hidden_dim, self.image_size * self.image_size).transpose(1, 2)  # [B, H*W, C]\n",
    "        x_norm = self.layer_norm(x)\n",
    "        attention_value, _ = self.att(x_norm, x_norm, x_norm)\n",
    "        x = x + attention_value\n",
    "        x = x + self.feed_forward(x)\n",
    "        x = x.transpose(1, 2).reshape(-1, self.hidden_dim, self.image_size, self.image_size)\n",
    "        return x\n",
    "\n",
    "class BottleNeckBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, groups=1):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, groups=groups)\n",
    "        self.norm = torch.nn.GroupNorm(groups, out_channels)\n",
    "        self.act = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class BaseConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False, groups=1):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.residual = residual\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False, groups=groups)\n",
    "        self.norm1 = torch.nn.GroupNorm(groups, mid_channels)\n",
    "        self.act1 = torch.nn.GELU()\n",
    "        self.conv2 = torch.nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False, groups=groups)\n",
    "        self.norm2 = torch.nn.GroupNorm(groups, out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        if self.residual:\n",
    "            x = torch.nn.functional.gelu(x + residual)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WaveDownSampleBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, wave='haar', groups=1):\n",
    "        super().__init__()\n",
    "        self.dwt = DWTForward(J=1, wave=wave, mode='symmetric')\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            BottleNeckBlock(in_channels * 4, in_channels, groups),  # Adjust Channels\n",
    "            BaseConvBlock(in_channels, in_channels, residual=True, groups=groups),\n",
    "            BaseConvBlock(in_channels, out_channels, groups=groups),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        xl, xh = self.dwt(x)\n",
    "        h = h//2\n",
    "        w = w//2\n",
    "        xh = xh[0][:, :, :, :h, :w]\n",
    "        xl = xl[:, :, :h, :w]\n",
    "        b, c, _, h, w = xh.shape\n",
    "        xh = xh.reshape(b, 3 * c, h, w)\n",
    "        x = torch.cat([xl, xh], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class WaveUpSampleBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, wave='haar', groups=1):\n",
    "        super().__init__()\n",
    "        self.bottle = BottleNeckBlock(in_channels // 2, 2 * in_channels, groups)\n",
    "        self.idwt = DWTInverse(wave=wave, mode='symmetric')\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            BaseConvBlock(in_channels, in_channels, residual=True), \n",
    "            BaseConvBlock(in_channels, out_channels, in_channels // 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip):  # Skip Connection\n",
    "        b, c, h, w = x.shape\n",
    "        x = self.bottle(x)\n",
    "        xl = x[:, :c]\n",
    "        xh = x[:, c:].reshape(b, c, 3, h, w)\n",
    "        h *= 2\n",
    "        w *= 2\n",
    "        x = self.idwt((xl, [xh]))\n",
    "        x = torch.nn.functional.pad(x, (0, h - x.shape[2], 0, w - x.shape[3]), 'reflect')\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class WaveUnet(torch.nn.Module):\n",
    "    def __init__(self, image_size, image_channels, wave='haar', beta_range=(1e-4, 0.02), groups=1, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.beta_range = beta_range\n",
    "        self.image_size = image_size\n",
    "        self.device = device\n",
    "        self.in_conv = BaseConvBlock(image_channels, 64)\n",
    "        self.down1 = WaveDownSampleBlock(64, 128, wave=wave, groups=groups)\n",
    "        self.down2 = WaveDownSampleBlock(128, 256, wave=wave, groups=groups)\n",
    "        self.att1 = ImageAttentionBlock(256, image_size // 4)\n",
    "        self.down3 = WaveDownSampleBlock(256, 256, wave=wave, groups=groups)\n",
    "        self.att2 = ImageAttentionBlock(256, image_size // 8)\n",
    "        self.up1 = WaveUpSampleBlock(512, 128, wave=wave, groups=groups)\n",
    "        self.att3 = ImageAttentionBlock(128, image_size // 4)\n",
    "        self.up2 = WaveUpSampleBlock(256, 64, wave=wave, groups=groups)\n",
    "        self.up3 = WaveUpSampleBlock(128, 64, wave=wave, groups=groups)\n",
    "        self.out_conv = torch.nn.Conv2d(64, image_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.in_conv(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.att1(x3)\n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.att2(x4)\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.att3(x)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137649c0-ea8a-499f-8525-0b670de26653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train, test\n",
    "from BSD import BSDDataset\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(4623)\n",
    "torch.cuda.manual_seed(4623)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_size = 256\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "base_dir = \"\"\n",
    "\n",
    "train_set = BSDDataset(base_dir=base_dir, split=\"train\")\n",
    "test_set = BSDDataset(base_dir=base_dir, split=\"test\")\n",
    "\n",
    "\n",
    "def rgb_to_ycbcr(img):\n",
    "    M = torch.tensor([[ 0.2990,     0.5870,     0.1140    ],\n",
    "                      [-0.168736, -0.331264,    0.5       ],\n",
    "                      [ 0.5,      -0.418688,   -0.081312  ]], dtype=img.dtype, device=img.device)\n",
    "    bias = torch.tensor([0.0, 0.5, 0.5], dtype=img.dtype, device=img.device).view(3, 1, 1)\n",
    "    ycbcr = torch.einsum('bchw,mc->bmhw', img, M) + bias\n",
    "    return ycbcr\n",
    "\n",
    "def ycbcr_to_rgb(ycbcr):\n",
    "    M_inv = torch.tensor([[1.0,  0.0,       1.402],\n",
    "                          [1.0, -0.344136, -0.714136],\n",
    "                          [1.0,  1.772,    0.0     ]], dtype=ycbcr.dtype, device=ycbcr.device)\n",
    "    bias = torch.tensor([0.0, -0.5, -0.5], dtype=ycbcr.dtype, device=ycbcr.device).view(3, 1, 1)\n",
    "    rgb = torch.einsum('bchw,mc->bmhw', ycbcr + bias, M_inv)\n",
    "    return rgb\n",
    "\n",
    "def compute_loss(model, images, noise_range=(1, 60), residual=False, luminance=False):\n",
    "    noise_level = torch.randint(noise_range[0], noise_range[1], (1,)).item()\n",
    "    noisy_images = images + (noise_level / 255.0) * torch.randn_like(images)\n",
    "    images = images.to(device)  # move to GPU\n",
    "    noisy_images = torch.clamp(noisy_images, 0, 1)\n",
    "    noisy_images = noisy_images.to(device)\n",
    "    if luminance:\n",
    "        images = rgb_to_ycbcr(images)[:, :1]\n",
    "        noisy_images = rgb_to_ycbcr(noisy_images)[:, :1]\n",
    "    outputs = model(noisy_images)  # forward\n",
    "    outputs = outputs\n",
    "    if residual:\n",
    "        loss = criterion(outputs, noisy_images - images)\n",
    "        return loss\n",
    "    loss = criterion(outputs, images)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def denoise(model, noisy_img, residual=False, luminance=False):\n",
    "    if luminance:\n",
    "        target_img = rgb_to_ycbcr(noisy_img)\n",
    "        noisy_img = target_img[:, :1]\n",
    "    if residual:\n",
    "        outputs = noisy_img - model(noisy_img)\n",
    "    else:\n",
    "        outputs = model(noisy_img)  # forward\n",
    "    if luminance:\n",
    "        outputs = torch.cat([outputs, target_img[:, 1:]], dim=1)\n",
    "        outputs = ycbcr_to_rgb(outputs)\n",
    "    outputs = torch.clamp(outputs, 0, 1)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3d5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(model_name, residual=False, luminance=False, groups=False):\n",
    "    if luminance:\n",
    "        model = WaveUnet(256, 1, groups=4 if groups else 1).to(device)\n",
    "    else:\n",
    "        model = WaveUnet(256, 3, groups=4 if groups else 1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train(model, optimizer, epochs, train_set, test_set, batch_size, model_name, compute_loss=compute_loss, residual=residual, luminance=luminance)\n",
    "    for noise_level in [10, 25, 50]:\n",
    "        test(model, test_set, batch_size, model_name, noise_level, denoise=denoise, residual=residual, luminance=luminance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: pytorch_wavelets in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-image in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.5.3.56 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from opencv-python-headless==4.5.3.56) (1.24.3)\n",
      "Requirement already satisfied: six in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pytorch_wavelets) (1.16.0)\n",
      "Requirement already satisfied: torch in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from pytorch_wavelets) (2.1.0+cu118)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (1.11.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: filelock in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (2024.9.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from torch->pytorch_wavelets) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from jinja2->torch->pytorch_wavelets) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/idies/miniconda3/envs/py39/lib/python3.9/site-packages (from sympy->torch->pytorch_wavelets) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyWavelets pytorch_wavelets scikit-image opencv-python-headless==4.5.3.56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160114f",
   "metadata": {},
   "source": [
    "All Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c0950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveUnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:53<?, ?it/s, Step=5/10000, training loss=0.289]"
     ]
    }
   ],
   "source": [
    "model_name = \"WaveUnet\"\n",
    "residual = True\n",
    "luminance = True\n",
    "groups=True\n",
    "\n",
    "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9b05c",
   "metadata": {},
   "source": [
    "Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3931d5-1f31-4f85-8b96-9e295a07df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:12:31<17:46, 106.66s/it, Step=4085/5000, training loss=0.002]"
     ]
    }
   ],
   "source": [
    "model_name = \"WaveUnet-no-residual\"\n",
    "residual = False\n",
    "luminance = True\n",
    "groups=True\n",
    "\n",
    "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cdc29-3e3a-4a55-bbca-783a90f56fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"WaveUnet-no-luminance\"\n",
    "residual = True\n",
    "luminance = False\n",
    "groups=True\n",
    "\n",
    "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31bc25-088e-4410-965c-7913e8de1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"WaveUnet-no-groups\"\n",
    "residual = True\n",
    "luminance = True\n",
    "groups=False\n",
    "\n",
    "experiment(model_name, residual=residual, luminance=luminance, groups=groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
